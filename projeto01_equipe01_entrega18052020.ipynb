{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "projeto01_equipe01_entrega27042020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodut/Mineracao_dados_textos_web/blob/master/projeto01_equipe01_entrega18052020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDkhltJeg5ag",
        "colab_type": "text"
      },
      "source": [
        "<b> EQUIPE: </b>\n",
        "  - Eduardo Fa√ßanha\n",
        "  - Giovanni Br√≠gido\n",
        "  - Maur√≠cio Brito\n",
        "\n",
        "<b> ATIVIDADE 01 </b> - Pr√©-processamento dos textos (Prazo: 11/05/2020 - 30%)\n",
        "\n",
        "- Tokeniza√ß√£o\n",
        "- Lematiza√ß√£o\n",
        "- POS Tagging\n",
        "- Normaliza√ß√£o (hashtags, men√ß√µes, emojis e s√≠mbolos especiais)\n",
        "- NER (entidades nomeadas)\n",
        "- Remo√ß√£o stop-words\n",
        "\n",
        "<b> ATIVIDADE 02 </b> - Representa√ß√£o Sem√¢ntica (Prazo: 22/06/2020 - 30%)\n",
        "\n",
        "- Uso de bases de conhecimento externas\n",
        "- Identifica√ß√£o de t√≥picos\n",
        "- Representa√ß√£o vetorial das palavras e textos\n",
        "\n",
        "<b> ATIVIDADE 03 </b> - Analise da Linguagem Ofensiva - Subtarefas A e B (Prazo: 27/07/2020 - 40%)\n",
        "\n",
        "- Resultado da subtarefa A para um conjunto de teste a ser fornecido\n",
        "- Resultado da subtarefa B para um conjunto de teste a ser fornecido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRQvNpQ79NTF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MRHH-jFQ9NhR"
      },
      "source": [
        "<b> Carregamento do arquivo de dados e transforma√ß√£o em DataFrame </b>\n",
        "\n",
        "√â realizado o download do arquivo e instanciado um DataFrame com os dados. A vari√°vel do DataFrame √© chamada 'tweets'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPX5dwMB9Fwb",
        "colab_type": "code",
        "outputId": "4a4108f7-b43c-4c23-b24b-b3e434b05074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "import pandas as pd\n",
        "#download o arquivo localizado no repos√≠t√≥rio do projeto\n",
        "!curl --remote-name \\\n",
        "    -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "    --location https://raw.githubusercontent.com/eduardodut/Mineracao_dados_textos_web/master/datasets/olid-training-v1.0.tsv\n",
        "\n",
        "#leitura para objeto dataframe\n",
        "tweets = pd.read_csv('/content/olid-training-v1.0.tsv', sep='\\t',encoding= 'utf-8')\n",
        "\n",
        "#convers√£o da coluna 'id' de inteiro para string\n",
        "tweets['id'] = tweets['id'].astype('str')\n",
        "\n",
        "#visualiza√ß√£o dos primeiros registros\n",
        "\n",
        "tweets = tweets[['subtask_c','subtask_b','subtask_a','id','tweet']]\n",
        "tweets.head(20)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 53 1915k   53 1022k    0     0  4316k      0 --:--:-- --:--:-- --:--:-- 4297k\r100 1915k  100 1915k    0     0  6200k      0 --:--:-- --:--:-- --:--:-- 6180k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>77444</td>\n",
              "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GRP</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>52415</td>\n",
              "      <td>@USER was literally just talking about this lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>45157</td>\n",
              "      <td>@USER Buy more icecream!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesn‚Äôt need another CUCK! We alr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>82776</td>\n",
              "      <td>@USER @USER @USER It‚Äôs not my fault you suppor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>42992</td>\n",
              "      <td>@USER What‚Äôs the difference between #Kavanaugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28414</td>\n",
              "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>54920</td>\n",
              "      <td>@USER @USER @USER It should scare every Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>56392</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>86735</td>\n",
              "      <td>@USER you are also the king of taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>95686</td>\n",
              "      <td>#MAGA @USER  üé∂ Sing like no one is listening  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>71446</td>\n",
              "      <td>5/5: @USER The time is right for this House to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>23958</td>\n",
              "      <td>@USER Besides Jax‚Äôs mom and maybe Ope he is ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28195</td>\n",
              "      <td>@USER @USER @USER gun control! That is all the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subtask_c  ...                                              tweet\n",
              "0        NaN  ...  @USER She should ask a few native Americans wh...\n",
              "1        IND  ...  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...\n",
              "2        NaN  ...  Amazon is investigating Chinese employees who ...\n",
              "3        NaN  ...  @USER Someone should'veTaken\" this piece of sh...\n",
              "4        NaN  ...  @USER @USER Obama wanted liberals &amp; illega...\n",
              "5        OTH  ...                  @USER Liberals are all Kookoo !!!\n",
              "6        NaN  ...                   @USER @USER Oh noes! Tough shit.\n",
              "7        GRP  ...  @USER was literally just talking about this lo...\n",
              "8        NaN  ...                         @USER Buy more icecream!!!\n",
              "9        IND  ...  @USER Canada doesn‚Äôt need another CUCK! We alr...\n",
              "10       NaN  ...  @USER @USER @USER It‚Äôs not my fault you suppor...\n",
              "11       NaN  ...  @USER What‚Äôs the difference between #Kavanaugh...\n",
              "12       IND  ...  @USER you are a lying corrupt traitor!!! Nobod...\n",
              "13       NaN  ...  @USER @USER @USER It should scare every Americ...\n",
              "14       NaN  ...  @USER @USER @USER @USER @USER @USER @USER @USE...\n",
              "15       NaN  ...               @USER you are also the king of taste\n",
              "16       NaN  ...  #MAGA @USER  üé∂ Sing like no one is listening  ...\n",
              "17       NaN  ...  5/5: @USER The time is right for this House to...\n",
              "18       NaN  ...  @USER Besides Jax‚Äôs mom and maybe Ope he is ha...\n",
              "19       OTH  ...  @USER @USER @USER gun control! That is all the...\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwWEaIDEcwF",
        "colab_type": "code",
        "outputId": "94ed2523-7700-4e5e-f5f4-a513c6c1cb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#verifica√ß√£o e remo√ß√£o de duplicatas\n",
        "if tweets.duplicated(['tweet']).sum()>0:\n",
        "  tweets.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
        "\n",
        "print('VALORES DUPLICADOS: ',tweets.duplicated(['tweet']).sum())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VALORES DUPLICADOS:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYbiDjILOK5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVAbRxcTLQZ0"
      },
      "source": [
        "<b> Tratamento inicial do texto </b>\n",
        "\n",
        "Converte o texto de cada tweet, separadamente, em min√∫sculo e remove espa√ßos e tabula√ß√µes extras. O resultado √© guardado no DataFrame tweets em uma nova coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqS-1g3Kwgi",
        "colab_type": "code",
        "outputId": "952ef122-6028-4b9d-a64f-447b88503792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "def tratamento_texto(tweet):\n",
        "  \n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.strip()\n",
        "  \n",
        "  #remove as men√ß√µes a usu√°rios de cada tweet\n",
        "  tweet = re.sub(r'@user', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as palavras url\n",
        "  tweet = re.sub(r'url', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as quebras de linha\n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  #substitui tabula√ß√µes por um espa√ßo em branco\n",
        "  tweet = re.sub(r'\\t', ' ', tweet)\n",
        "  #substitui um ou mais espa√ßos em branco por um espa√ßo\n",
        "  tweet= re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
        "  #&amp;\n",
        "  #remove aspas e ap√≥stofres\n",
        "  # tweet = re.sub('[\\'\"‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', tweet)\n",
        "  return tweet\n",
        "\n",
        "#cria uma nova coluna no dataframe 'tweets' com cada tweet tokenizado\n",
        "tweets['tweet_tratado'] = tweets['tweet'].apply(tratamento_texto)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[go, home, youre, drunk, !, !, !, #maga, #trum...</td>\n",
              "      <td>[go home youre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[someone, shouldvetaken, this, piece, of, shit...</td>\n",
              "      <td>[someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [(she, PRP), (should, MD), (ask, VB), (a, DT),...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (youre, NN), (drunk, NN...  ...       IND\n",
              "2  [(amazon, NN), (is, VBZ), (investigating, VBG)...  ...       NaN\n",
              "3  [(someone, NN), (shouldvetaken, VBD), (this, D...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzoy4baWLizj"
      },
      "source": [
        "<b> Separa√ß√£o em senten√ßas </b>\n",
        "\n",
        "Separa cada tweet em senten√ßas e os coloca no DataFrame, em uma nova coluna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qma4M_noK4zu",
        "colab_type": "code",
        "outputId": "25ae23b0-468c-4ae6-9aaa-e6fc2aa9fcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "import nltk\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "  nltk.download(\"stopwords\") \n",
        "  nltk.download('punkt')\n",
        "\n",
        "def separa_sentencas(tweet):\n",
        "  \n",
        "  lista_sentencas = sent_tokenize(tweet)\n",
        "  # lista_setencas.str.strip()\n",
        "  nova_lista = []\n",
        "  for sent in lista_sentencas:\n",
        "    nova_lista.append(sent.strip())\n",
        "\n",
        "  return nova_lista #retorna lista de senten√ßas com a fun√ß√£o .strip() aplicada\n",
        "tweets['tweet_em_sentencas'] = tweets['tweet_tratado'].apply(separa_sentencas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[go, home, youre, drunk, !, !, !, #maga, #trum...</td>\n",
              "      <td>[go home you‚Äôre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[someone, shouldvetaken, this, piece, of, shit...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [(she, PRP), (should, MD), (ask, VB), (a, DT),...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (youre, NN), (drunk, NN...  ...       IND\n",
              "2  [(amazon, NN), (is, VBZ), (investigating, VBG)...  ...       NaN\n",
              "3  [(someone, NN), (shouldvetaken, VBD), (this, D...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TZXVEs_1L3dj"
      },
      "source": [
        "<b> Tokeniza√ß√£o </b>\n",
        "\n",
        "Re√∫ne as senten√ßas em uma string √∫nica e realiza a tokeniza√ß√£o do tweet. O resultado pode ser observado em uma nova coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y7Kz7aOLCzn",
        "colab_type": "code",
        "outputId": "e19075a2-efc2-41e6-bdc5-924c52d997bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "def tokeniza_sentenca(lista_sentencas):\n",
        "  tokenizer = TweetTokenizer()\n",
        "  #uni√£o das senten√ßas\n",
        "  sentencas_unidas = \" \".join(w for w in lista_sentencas)\n",
        "  #tokeniza√ß√£o das senten√ßas unidas\n",
        "  tokens = tokenizer.tokenize(sentencas_unidas)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tweets['tweet_tokenizado'] = tweets['tweet_em_sentencas'].apply(tokeniza_sentenca)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[go, home, you, ‚Äô, re, drunk, !, !, !, #maga, ...</td>\n",
              "      <td>[go home you‚Äôre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[someone, should'vetaken, \", this, piece, of, ...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [(she, PRP), (should, MD), (ask, VB), (a, DT),...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (youre, NN), (drunk, NN...  ...       IND\n",
              "2  [(amazon, NN), (is, VBZ), (investigating, VBG)...  ...       NaN\n",
              "3  [(someone, NN), (shouldvetaken, VBD), (this, D...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gc2ojEgN8CAz"
      },
      "source": [
        "<b> POS Tagger </b>\n",
        "\n",
        "Realiza a part of speech tagging do texto de cada token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO70tP5r8NtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "7e3211de-fde8-47a7-d327-47d81d384588"
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tweets['tweet_POS_tagged'] = tweets['tweet_tokenizado'].apply(nltk.pos_tag)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (youre, NN), (drunk, NN...</td>\n",
              "      <td>[(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...</td>\n",
              "      <td>[go, home, you, ‚Äô, re, drunk, !, !, !, #maga, ...</td>\n",
              "      <td>[go home you‚Äôre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (shouldvetaken, VBD), (this, D...</td>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (\", PDT...</td>\n",
              "      <td>[someone, should'vetaken, \", this, piece, of, ...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [(she, PRP), (should, MD), (ask, VB), (a, DT),...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (youre, NN), (drunk, NN...  ...       IND\n",
              "2  [(amazon, NN), (is, VBZ), (investigating, VBG)...  ...       NaN\n",
              "3  [(someone, NN), (shouldvetaken, VBD), (this, D...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSeX_Mt8DnbX"
      },
      "source": [
        "<b> NER </b>\n",
        "\n",
        "Realiza a reconhecimento de entidades, NER, a partir da coluna com os tokens taggeados do tweet: ['tweet_POS_tagged']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6b93596f-0f8f-429d-ece9-31f4138ae753",
        "id": "U9gYrTCrDnbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "from nltk.chunk.regexp import ChunkString, ChunkRule, ChinkRule \n",
        "from nltk.tree import Tree \n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "    nltk.download('words')\n",
        "\n",
        "tweets['tweet_NER'] = tweets['tweet_POS_tagged'].apply(nltk.ne_chunk)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...</td>\n",
              "      <td>[(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...</td>\n",
              "      <td>[go, home, you, ‚Äô, re, drunk, !, !, !, #maga, ...</td>\n",
              "      <td>[go home you‚Äôre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (\", PDT...</td>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (\", PDT...</td>\n",
              "      <td>[someone, should'vetaken, \", this, piece, of, ...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [(she, PRP), (should, MD), (ask, VB), (a, DT),...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...  ...       IND\n",
              "2  [(amazon, NN), (is, VBZ), (investigating, VBG)...  ...       NaN\n",
              "3  [(someone, NN), (should'vetaken, VBD), (\", PDT...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I36muOKnMD4D"
      },
      "source": [
        "<b> Remo√ß√£o de stop words </b>\n",
        "\n",
        "Remove da lista de tokens de cada tweet as stop words da l√≠ngua inglesa e pontua√ß√µes.\n",
        "S√£o retiradas as stop words das colunas ['tweet_ner'] e ['tweet_tokenizado']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcCFILRLFFp",
        "colab_type": "code",
        "outputId": "8a5ed2e1-6dd6-4d92-af83-9ad19ee337cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "# import string library function  \n",
        "from string import punctuation\n",
        "    \n",
        "\n",
        "\n",
        "def remove_stop_words(lista_tokens):\n",
        "  '''Fun√ß√£o de remo√ß√£o de stop word que recebe lista de tokens e devolve\n",
        "  lista de tokens\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "\n",
        "  tokens = [w for w in lista_tokens if not w in stop_words]\n",
        "\n",
        "  return tokens\n",
        "\n",
        "def remove_stop_words_tuplas(lista_tuplas):\n",
        "  '''Fun√ß√£o de remo√ß√£o de stop word que recebe lista de tuplas de token e tag e devolve\n",
        "  lista de tuplas de token e tag\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "\n",
        "  tuplas = [w for w in lista_tuplas if not w[0] in stop_words]\n",
        "\n",
        "  return tuplas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tweets['tokens_sem_stopwords'] = tweets['tweet_tokenizado'].apply(remove_stop_words)\n",
        "tweets['NER_sem_stopwords'] = tweets['tweet_NER'].apply(remove_stop_words_tuplas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>tokens_sem_stopwords</th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(ask, VB), (native, JJ), (americans, NNS), (t...</td>\n",
              "      <td>[ask, native, americans, take]</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[(she, PRP), (should, MD), (ask, VB), (a, DT),...</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (‚Äô, VBP), (drunk, NN), ...</td>\n",
              "      <td>[go, home, ‚Äô, drunk, #maga, #trump2020, üëä, üá∫, ...</td>\n",
              "      <td>[(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...</td>\n",
              "      <td>[(go, VB), (home, NN), (you, PRP), (‚Äô, VBP), (...</td>\n",
              "      <td>[go, home, you, ‚Äô, re, drunk, !, !, !, #maga, ...</td>\n",
              "      <td>[go home you‚Äôre drunk!!!, #maga #trump2020 üëäüá∫üá∏üëä]</td>\n",
              "      <td>go home you‚Äôre drunk!!! #maga #trump2020 üëäüá∫üá∏üëä</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (investigating, VBG), (chinese,...</td>\n",
              "      <td>[amazon, investigating, chinese, employees, se...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[(amazon, NN), (is, VBZ), (investigating, VBG)...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (piece,...</td>\n",
              "      <td>[someone, should'vetaken, piece, shit, volcano...</td>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (\", PDT...</td>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (\", PDT...</td>\n",
              "      <td>[someone, should'vetaken, \", this, piece, of, ...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, illegals, move, red,...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   NER_sem_stopwords  ... subtask_c\n",
              "0  [(ask, VB), (native, JJ), (americans, NNS), (t...  ...       NaN\n",
              "1  [(go, VB), (home, NN), (‚Äô, VBP), (drunk, NN), ...  ...       IND\n",
              "2  [(amazon, NN), (investigating, VBG), (chinese,...  ...       NaN\n",
              "3  [(someone, NN), (should'vetaken, VBD), (piece,...  ...       NaN\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  ...       NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gpvnfgkKLFB5"
      },
      "source": [
        "<b> Fim da atividade 01 </b>\n",
        "\n",
        "Tem-se como principais entregas as colunas tweets['tokens_sem_stopwords'] e tweets['NER_sem_stopwords'] do dataset tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0KRyOaLU5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5550196b-536b-4100-af70-09ce3598873f"
      },
      "source": [
        "tweets[['NER_sem_stopwords','tokens_sem_stopwords']].head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>tokens_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(ask, VB), (native, JJ), (americans, NNS), (t...</td>\n",
              "      <td>[ask, native, americans, take]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(go, VB), (home, NN), (‚Äô, VBP), (drunk, NN), ...</td>\n",
              "      <td>[go, home, ‚Äô, drunk, #maga, #trump2020, üëä, üá∫, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(amazon, NN), (investigating, VBG), (chinese,...</td>\n",
              "      <td>[amazon, investigating, chinese, employees, se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(someone, NN), (should'vetaken, VBD), (piece,...</td>\n",
              "      <td>[someone, should'vetaken, piece, shit, volcano...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(obama, RB), (wanted, VBD), (liberals, NNS), ...</td>\n",
              "      <td>[obama, wanted, liberals, illegals, move, red,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   NER_sem_stopwords                               tokens_sem_stopwords\n",
              "0  [(ask, VB), (native, JJ), (americans, NNS), (t...                     [ask, native, americans, take]\n",
              "1  [(go, VB), (home, NN), (‚Äô, VBP), (drunk, NN), ...  [go, home, ‚Äô, drunk, #maga, #trump2020, üëä, üá∫, ...\n",
              "2  [(amazon, NN), (investigating, VBG), (chinese,...  [amazon, investigating, chinese, employees, se...\n",
              "3  [(someone, NN), (should'vetaken, VBD), (piece,...  [someone, should'vetaken, piece, shit, volcano...\n",
              "4  [(obama, RB), (wanted, VBD), (liberals, NNS), ...  [obama, wanted, liberals, illegals, move, red,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkVlpDzLWf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}