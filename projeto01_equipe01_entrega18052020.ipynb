{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "projeto01_equipe01_entrega27042020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodut/Mineracao_dados_textos_web/blob/master/projeto01_equipe01_entrega18052020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDkhltJeg5ag",
        "colab_type": "text"
      },
      "source": [
        "<b> EQUIPE: </b>\n",
        "  - Eduardo Façanha\n",
        "  - Giovanni Brígido\n",
        "  - Maurício Brito\n",
        "\n",
        "<b> ATIVIDADE 01 </b> - Pré-processamento dos textos (Prazo: 11/05/2020 - 30%)\n",
        "\n",
        "- Tokenização\n",
        "- Lematização\n",
        "- POS Tagging\n",
        "- Normalização (hashtags, menções, emojis e símbolos especiais)\n",
        "- Chunking\n",
        "- NER (entidades nomeadas)\n",
        "- Remoção stop-words\n",
        "\n",
        "<b> ATIVIDADE 02 </b> - Representação Semântica (Prazo: 22/06/2020 - 30%)\n",
        "\n",
        "- Uso de bases de conhecimento externas\n",
        "- Identificação de tópicos\n",
        "- Representação vetorial das palavras e textos\n",
        "\n",
        "<b> ATIVIDADE 03 </b> - Analise da Linguagem Ofensiva - Subtarefas A e B (Prazo: 27/07/2020 - 40%)\n",
        "\n",
        "- Resultado da subtarefa A para um conjunto de teste a ser fornecido\n",
        "- Resultado da subtarefa B para um conjunto de teste a ser fornecido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRQvNpQ79NTF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MRHH-jFQ9NhR"
      },
      "source": [
        "<b> Carregamento do arquivo de dados e transformação em DataFrame </b>\n",
        "\n",
        "É realizado o download do arquivo e instanciado um DataFrame com os dados. A variável do DataFrame é chamada 'tweets'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPX5dwMB9Fwb",
        "colab_type": "code",
        "outputId": "fde0428d-946f-45c2-863b-faf074936bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "import pandas as pd\n",
        "#download o arquivo localizado no reposítório do projeto\n",
        "!curl --remote-name \\\n",
        "    -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "    --location https://raw.githubusercontent.com/eduardodut/Mineracao_dados_textos_web/master/datasets/olid-training-v1.0.tsv\n",
        "\n",
        "#leitura para objeto dataframe\n",
        "tweets = pd.read_csv('/content/olid-training-v1.0.tsv', sep='\\t',encoding= 'utf-8')\n",
        "\n",
        "#conversão da coluna 'id' de inteiro para string\n",
        "tweets['id'] = tweets['id'].astype('str')\n",
        "\n",
        "#visualização dos primeiros registros\n",
        "\n",
        "tweets = tweets[['subtask_c','subtask_b','subtask_a','id','tweet']]\n",
        "tweets.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 1915k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1915k  100 1915k    0     0  3007k      0 --:--:-- --:--:-- --:--:-- 3003k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>77444</td>\n",
              "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GRP</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>52415</td>\n",
              "      <td>@USER was literally just talking about this lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>45157</td>\n",
              "      <td>@USER Buy more icecream!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>82776</td>\n",
              "      <td>@USER @USER @USER It’s not my fault you suppor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>42992</td>\n",
              "      <td>@USER What’s the difference between #Kavanaugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28414</td>\n",
              "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>54920</td>\n",
              "      <td>@USER @USER @USER It should scare every Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>56392</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>86735</td>\n",
              "      <td>@USER you are also the king of taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>95686</td>\n",
              "      <td>#MAGA @USER  🎶 Sing like no one is listening  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>71446</td>\n",
              "      <td>5/5: @USER The time is right for this House to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>23958</td>\n",
              "      <td>@USER Besides Jax’s mom and maybe Ope he is ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28195</td>\n",
              "      <td>@USER @USER @USER gun control! That is all the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subtask_c  ...                                              tweet\n",
              "0        NaN  ...  @USER She should ask a few native Americans wh...\n",
              "1        IND  ...  @USER @USER Go home you’re drunk!!! @USER #MAG...\n",
              "2        NaN  ...  Amazon is investigating Chinese employees who ...\n",
              "3        NaN  ...  @USER Someone should'veTaken\" this piece of sh...\n",
              "4        NaN  ...  @USER @USER Obama wanted liberals &amp; illega...\n",
              "5        OTH  ...                  @USER Liberals are all Kookoo !!!\n",
              "6        NaN  ...                   @USER @USER Oh noes! Tough shit.\n",
              "7        GRP  ...  @USER was literally just talking about this lo...\n",
              "8        NaN  ...                         @USER Buy more icecream!!!\n",
              "9        IND  ...  @USER Canada doesn’t need another CUCK! We alr...\n",
              "10       NaN  ...  @USER @USER @USER It’s not my fault you suppor...\n",
              "11       NaN  ...  @USER What’s the difference between #Kavanaugh...\n",
              "12       IND  ...  @USER you are a lying corrupt traitor!!! Nobod...\n",
              "13       NaN  ...  @USER @USER @USER It should scare every Americ...\n",
              "14       NaN  ...  @USER @USER @USER @USER @USER @USER @USER @USE...\n",
              "15       NaN  ...               @USER you are also the king of taste\n",
              "16       NaN  ...  #MAGA @USER  🎶 Sing like no one is listening  ...\n",
              "17       NaN  ...  5/5: @USER The time is right for this House to...\n",
              "18       NaN  ...  @USER Besides Jax’s mom and maybe Ope he is ha...\n",
              "19       OTH  ...  @USER @USER @USER gun control! That is all the...\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwWEaIDEcwF",
        "colab_type": "code",
        "outputId": "1d6779c0-82ff-4bdb-9454-44e5b8f1784d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#verificação e remoção de duplicatas\n",
        "if tweets.duplicated(['tweet']).sum()>0:\n",
        "  tweets.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
        "\n",
        "print('TWEETS DUPLICADOS: ',tweets.duplicated(['tweet']).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TWEETS DUPLICADOS:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVAbRxcTLQZ0"
      },
      "source": [
        "<b> Tratamento inicial do texto </b>\n",
        "\n",
        "Converte o texto de cada tweet, separadamente, em minúsculo e remove espaços e tabulações extras. O resultado é guardado no DataFrame tweets em uma nova coluna.\n",
        "\n",
        "Entrada: tweets['tweet']<br/>\n",
        "Saída: tweets['tweet_tratado']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqS-1g3Kwgi",
        "colab_type": "code",
        "outputId": "6ac9f005-46da-48e9-a533-38e13551d545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "def tratamento_texto(tweet):\n",
        "  \n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.strip()\n",
        "  \n",
        "  #remove as menções a usuários de cada tweet\n",
        "  # tweet = re.sub(r'@user', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as palavras url\n",
        "  tweet = re.sub(r'url', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as quebras de linha\n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  #substitui tabulações por um espaço em branco\n",
        "  tweet = re.sub(r'\\t', ' ', tweet)\n",
        "  #substitui um ou mais espaços em branco por um espaço\n",
        "  tweet= re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
        "  #&amp;\n",
        "  #remove aspas e apóstofres\n",
        "  # tweet = re.sub('[\\'\"‘’“”…]', '', tweet)\n",
        "  return tweet\n",
        "\n",
        "#cria uma nova coluna no dataframe 'tweets' com cada tweet tokenizado\n",
        "tweets['tweet_tratado'] = tweets['tweet'].apply(tratamento_texto)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_tratado  ... subtask_c\n",
              "0   she should ask a few native americans what th...  ...       NaN\n",
              "1     go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊   ...       IND\n",
              "2  amazon is investigating chinese employees who ...  ...       NaN\n",
              "3   someone should'vetaken\" this piece of shit to...  ...       NaN\n",
              "4   obama wanted liberals &amp; illegals to move ...  ...       NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzoy4baWLizj"
      },
      "source": [
        "<b> Separação em sentenças </b>\n",
        "\n",
        "Separa cada tweet em sentenças.\n",
        "\n",
        "Entrada: tweets['tweet_tratado']<br/>\n",
        "Saída: tweets['tweet_em_sentencas']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qma4M_noK4zu",
        "colab_type": "code",
        "outputId": "d6afa69d-fae0-457d-e905-e7fad19bd58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "import nltk\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "  nltk.download(\"stopwords\") \n",
        "  nltk.download('punkt')\n",
        "\n",
        "def separa_sentencas(tweet):\n",
        "  \n",
        "  lista_sentencas = sent_tokenize(tweet)\n",
        "  # lista_setencas.str.strip()\n",
        "  nova_lista = []\n",
        "  for sent in lista_sentencas:\n",
        "    nova_lista.append(sent.strip())\n",
        "\n",
        "  return nova_lista #retorna lista de sentenças com a função .strip() aplicada\n",
        "tweets['tweet_em_sentencas'] = tweets['tweet_tratado'].apply(separa_sentencas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  tweet_em_sentencas  ... subtask_c\n",
              "0  [she should ask a few native americans what th...  ...       NaN\n",
              "1   [go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]  ...       IND\n",
              "2  [amazon is investigating chinese employees who...  ...       NaN\n",
              "3  [someone should'vetaken\" this piece of shit to...  ...       NaN\n",
              "4  [obama wanted liberals &amp; illegals to move ...  ...       NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TZXVEs_1L3dj"
      },
      "source": [
        "<b> Tokenização </b>\n",
        "\n",
        "Tokenização do tweet.\n",
        "\n",
        "Entrada: tweets['tweet_em_sentencas']<br/>\n",
        "Saída: tweets['tweet_tokenizado']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y7Kz7aOLCzn",
        "colab_type": "code",
        "outputId": "08cff7d5-424d-4806-d40b-24a9a54f09da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "def tokeniza_sentenca(lista_sentencas):\n",
        "  # tokenizer = TweetTokenizer()\n",
        "  # #união das sentenças\n",
        "  # sentencas_unidas = \" \".join(w for w in lista_sentencas)\n",
        "  # #tokenização das sentenças unidas\n",
        "  # tokens = tokenizer.tokenize(sentencas_unidas)\n",
        "\n",
        "  tokenizer = TweetTokenizer()\n",
        "  tokens = []\n",
        "\n",
        "  for sentenca in lista_sentencas:\n",
        "\n",
        "    tokens.append(tokenizer.tokenize(sentenca))\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tweets['tweet_tokenizado'] = tweets['tweet_em_sentencas'].apply(tokeniza_sentenca)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[go, home, you, ’, re, drunk, !, !, !], [#mag...</td>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[someone, should'vetaken, \", this, piece, of,...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tweet_tokenizado  ... subtask_c\n",
              "0  [[she, should, ask, a, few, native, americans,...  ...       NaN\n",
              "1  [[go, home, you, ’, re, drunk, !, !, !], [#mag...  ...       IND\n",
              "2  [[amazon, is, investigating, chinese, employee...  ...       NaN\n",
              "3  [[someone, should'vetaken, \", this, piece, of,...  ...       NaN\n",
              "4  [[obama, wanted, liberals, &, illegals, to, mo...  ...       NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gc2ojEgN8CAz"
      },
      "source": [
        "<b> POS Tagger </b>\n",
        "\n",
        "Realiza a part of speech tagging do texto de cada token\n",
        "\n",
        "Entrada: tweets['tweet_tokenizado']<br/>\n",
        "Saída: tweets['tweet_POS_tagged']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO70tP5r8NtQ",
        "colab_type": "code",
        "outputId": "6159198b-a3d6-41d9-c94d-9a8da02da33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "# a função map aplica a funcao nltk.post_tag para cada lista contida da coluna tweet tokenizado\n",
        " \n",
        "def pos_taggeador(lista_tokens):\n",
        "  setenca_taggeada = []\n",
        "  for lista in lista_tokens:\n",
        "    setenca_taggeada.append(nltk.pos_tag(lista))\n",
        "\n",
        "  return setenca_taggeada\n",
        "\n",
        "                                                        #apply(nltk.pos) se a coluna for composta de lista de tokens\n",
        "tweets['tweet_POS_tagged'] = tweets['tweet_tokenizado'].apply(pos_taggeador)#\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[go, home, you, ’, re, drunk, !, !, !], [#mag...</td>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[someone, should'vetaken, \", this, piece, of,...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tweet_POS_tagged  ... subtask_c\n",
              "0  [[(she, PRP), (should, MD), (ask, VB), (a, DT)...  ...       NaN\n",
              "1  [[(go, VB), (home, NN), (you, PRP), (’, VBP), ...  ...       IND\n",
              "2  [[(amazon, NN), (is, VBZ), (investigating, VBG...  ...       NaN\n",
              "3  [[(someone, NN), (should'vetaken, VBD), (\", PD...  ...       NaN\n",
              "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...  ...       NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGo5JNKZuK-N",
        "colab_type": "text"
      },
      "source": [
        "**Chunking**\n",
        "\n",
        "Separação de cada sentença em chunks. \n",
        "\n",
        "Entrada: tweets['tweet_POS_tagged']<br/>\n",
        "Saída: tweets['tweet_chunked']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0Uhw6uuLR7",
        "colab_type": "code",
        "outputId": "c3960c0b-cc0c-4f28-fbf5-d0eec74ae1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "\n",
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "pattern1 = 'NP: {<DT>?<JJ>*<NN.*>*}'\n",
        "pattern2 = 'NP: {<DT><NN.*><.*>*<NN.*>}'\n",
        "\n",
        "def chunker(lista_tweets_pos_tagged):\n",
        "\n",
        "  lista_saida = []\n",
        "\n",
        "  pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "  pattern1 = 'NP: {<DT>?<JJ>*<NN.*>*}'\n",
        "  pattern2 = 'NP: {<DT><NN.*><.*>*<NN.*>}'\n",
        "\n",
        "\n",
        "  for lista in lista_tweets_pos_tagged:\n",
        "    cp = nltk.RegexpParser(pattern1)\n",
        "    cs = cp.parse(lista)\n",
        "    iob_tagged = tree2conlltags(cs)\n",
        "    \n",
        "    lista_saida.append(iob_tagged)\n",
        "  return lista_saida\n",
        "\n",
        "\n",
        "tweets['tweet_chunked'] = tweets['tweet_POS_tagged'].apply(chunker)\n",
        "\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_chunked</th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(she, PRP, O), (should, MD, O), (ask, VB, O)...</td>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB, O), (home, NN, B-NP), (you, PRP, O)...</td>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[go, home, you, ’, re, drunk, !, !, !], [#mag...</td>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN, B-NP), (is, VBZ, O), (investiga...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN, B-NP), (should'vetaken, VBD, O...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[someone, should'vetaken, \", this, piece, of,...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_chunked  ... subtask_c\n",
              "0  [[(she, PRP, O), (should, MD, O), (ask, VB, O)...  ...       NaN\n",
              "1  [[(go, VB, O), (home, NN, B-NP), (you, PRP, O)...  ...       IND\n",
              "2  [[(amazon, NN, B-NP), (is, VBZ, O), (investiga...  ...       NaN\n",
              "3  [[(someone, NN, B-NP), (should'vetaken, VBD, O...  ...       NaN\n",
              "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...  ...       NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSeX_Mt8DnbX"
      },
      "source": [
        "<b> NER </b>\n",
        "\n",
        "Realiza a reconhecimento de entidades, NER.\n",
        "\n",
        "Entrada: tweets['tweet_POS_tagged']<br/>\n",
        "Saída: tweets['tweet_NER']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "004d2ff4-0e66-4f8b-f48a-abff2ffa32d9",
        "id": "U9gYrTCrDnbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "from nltk.chunk.regexp import ChunkString, ChunkRule, ChinkRule \n",
        "from nltk.tree import Tree \n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "    nltk.download('words')\n",
        "\n",
        "def ner(lista_tokens_taggeados):\n",
        "  lista_tokens_ner = []\n",
        "  for lista in lista_tokens_taggeados:\n",
        "    lista_tokens_ner.append(nltk.ne_chunk(lista))\n",
        "\n",
        "  return lista_tokens_ner\n",
        "\n",
        "\n",
        "tweets['tweet_NER'] = tweets['tweet_POS_tagged'].apply(ner)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[go, home, you, ’, re, drunk, !, !, !], [#mag...</td>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[someone, should'vetaken, \", this, piece, of,...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [[(she, PRP), (should, MD), (ask, VB), (a, DT)...  ...       NaN\n",
              "1  [[(go, VB), (home, NN), (you, PRP), (’, VBP), ...  ...       IND\n",
              "2  [[(amazon, NN), (is, VBZ), (investigating, VBG...  ...       NaN\n",
              "3  [[(someone, NN), (should'vetaken, VBD), (\", PD...  ...       NaN\n",
              "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I36muOKnMD4D"
      },
      "source": [
        "<b> Remoção de stop words </b>\n",
        "\n",
        "Remove da lista de tokens de cada tweet as stop words da língua inglesa e pontuações.\n",
        "\n",
        "Entradas:<br/>\n",
        "         * tweets['tweet_tokenizado']<br/>\n",
        "         * tweets['tweet_ner']<br/>\n",
        "         * tweets['tweet_chunked']<br/>\n",
        "\n",
        "Saída:<br/>\n",
        "         * tweets['tokens_sem_stopwords']<br/>\n",
        "         * tweets['NER_sem_stopwords'] <br/>\n",
        "         * tweets['chunks_sem_stopwords']<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcCFILRLFFp",
        "colab_type": "code",
        "outputId": "da359af5-6601-4120-f455-6c7fb546ca2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "# import string library function  \n",
        "from string import punctuation\n",
        "    \n",
        "\n",
        "\n",
        "def remove_stop_words(lista_token_sentenca):\n",
        "  '''Função de remoção de stop word que recebe lista de tokens e devolve\n",
        "  lista de tokens\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "\n",
        "  lista_saida = []\n",
        "\n",
        "  for lista_tokens in lista_token_sentenca:\n",
        "    tokens = [w for w in lista_tokens if not w in stop_words]\n",
        "    lista_saida.append(tokens)\n",
        "\n",
        "\n",
        "  return lista_saida\n",
        "\n",
        "def remove_stop_words_tuplas(lista_tuplas_sentencas):\n",
        "  '''Função de remoção de stop word que recebe lista de tuplas de token e tag e devolve\n",
        "  lista de tuplas de token e tag\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "  lista_saida = []\n",
        "  for lista_tuplas in lista_tuplas_sentencas:\n",
        "    tuplas = [w for w in lista_tuplas if not w[0] in stop_words]\n",
        "    lista_saida.append(tuplas)\n",
        "  return lista_saida\n",
        "\n",
        "tweets['tokens_sem_stopwords'] = tweets['tweet_tokenizado'].apply(remove_stop_words)\n",
        "tweets['NER_sem_stopwords'] = tweets['tweet_NER'].apply(remove_stop_words_tuplas)\n",
        "tweets['chunks_sem_stopwords'] = tweets['tweet_chunked'].apply(remove_stop_words_tuplas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunks_sem_stopwords</th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>tokens_sem_stopwords</th>\n",
              "      <th>tweet_chunked</th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(ask, VB, O), (native, JJ, I-NP), (americans...</td>\n",
              "      <td>[[(ask, VB), (native, JJ), (americans, NNS), (...</td>\n",
              "      <td>[[ask, native, americans, take]]</td>\n",
              "      <td>[[(she, PRP, O), (should, MD, O), (ask, VB, O)...</td>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[(she, PRP), (should, MD), (ask, VB), (a, DT)...</td>\n",
              "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...</td>\n",
              "      <td>[[(go, VB), (home, NN), (’, VBP), (drunk, NN)]...</td>\n",
              "      <td>[[go, home, ’, drunk], [#maga, #trump2020, 👊, ...</td>\n",
              "      <td>[[(go, VB, O), (home, NN, B-NP), (you, PRP, O)...</td>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[(go, VB), (home, NN), (you, PRP), (’, VBP), ...</td>\n",
              "      <td>[[go, home, you, ’, re, drunk, !, !, !], [#mag...</td>\n",
              "      <td>[go home you’re drunk!!!, #maga #trump2020 👊🇺🇸👊]</td>\n",
              "      <td>go home you’re drunk!!! #maga #trump2020 👊🇺🇸👊</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
              "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
              "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
              "      <td>[[(amazon, NN, B-NP), (is, VBZ, O), (investiga...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN, B-NP), (should'vetaken, VBD, O...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (piece...</td>\n",
              "      <td>[[someone, should'vetaken, piece, shit, volcan...</td>\n",
              "      <td>[[(someone, NN, B-NP), (should'vetaken, VBD, O...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (\", PD...</td>\n",
              "      <td>[[someone, should'vetaken, \", this, piece, of,...</td>\n",
              "      <td>[someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>someone should'vetaken\" this piece of shit to...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[obama, wanted, liberals, illegals, move, red...</td>\n",
              "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                chunks_sem_stopwords  ... subtask_c\n",
              "0  [[(ask, VB, O), (native, JJ, I-NP), (americans...  ...       NaN\n",
              "1  [[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...  ...       IND\n",
              "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...  ...       NaN\n",
              "3  [[(someone, NN, B-NP), (should'vetaken, VBD, O...  ...       NaN\n",
              "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...  ...       NaN\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gpvnfgkKLFB5"
      },
      "source": [
        "<b> Fim da atividade 01 </b>\n",
        "\n",
        "Tem-se como principais entregas as colunas tweets['tokens_sem_stopwords'] e tweets['NER_sem_stopwords'] do dataset tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0KRyOaLU5H",
        "colab_type": "code",
        "outputId": "f439130b-cd4b-4af6-b6bb-6ef0244df0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "tweets[['NER_sem_stopwords','chunks_sem_stopwords']].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>chunks_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(ask, VB), (native, JJ), (americans, NNS), (...</td>\n",
              "      <td>[[(ask, VB, O), (native, JJ, I-NP), (americans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB), (home, NN), (’, VBP), (drunk, NN)]...</td>\n",
              "      <td>[[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
              "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (piece...</td>\n",
              "      <td>[[(someone, NN, B-NP), (should'vetaken, VBD, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   NER_sem_stopwords                               chunks_sem_stopwords\n",
              "0  [[(ask, VB), (native, JJ), (americans, NNS), (...  [[(ask, VB, O), (native, JJ, I-NP), (americans...\n",
              "1  [[(go, VB), (home, NN), (’, VBP), (drunk, NN)]...  [[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...\n",
              "2  [[(amazon, NN), (investigating, VBG), (chinese...  [[(amazon, NN, B-NP), (investigating, VBG, O),...\n",
              "3  [[(someone, NN), (should'vetaken, VBD), (piece...  [[(someone, NN, B-NP), (should'vetaken, VBD, O...\n",
              "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...  [[(obama, RB, O), (wanted, VBD, O), (liberals,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkVlpDzLWf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}