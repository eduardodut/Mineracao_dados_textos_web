{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "projeto01_equipe01_entrega27042020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodut/Mineracao_dados_textos_web/blob/master/projeto01_equipe01_entrega27042020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDkhltJeg5ag",
        "colab_type": "text"
      },
      "source": [
        "<b> EQUIPE: </b>\n",
        "  - Eduardo Façanha\n",
        "  - Giovanni Brígido\n",
        "  - Maurício Brito\n",
        "\n",
        "<b> ATIVIDADE 01 </b> - Pré-processamento dos textos (Prazo: 11/05/2020 - 30%)\n",
        "\n",
        "- Tokenização\n",
        "- Lematização\n",
        "- POS Tagging\n",
        "- Normalização (hashtags, menções, emojis e símbolos especiais)\n",
        "- NER (entidades nomeadas)\n",
        "- Remoção stop-words\n",
        "\n",
        "<b> ATIVIDADE 02 </b> - Representação Semântica (Prazo: 22/06/2020 - 30%)\n",
        "\n",
        "- Uso de bases de conhecimento externas\n",
        "- Identificação de tópicos\n",
        "- Representação vetorial das palavras e textos\n",
        "\n",
        "<b> ATIVIDADE 03 </b> - Analise da Linguagem Ofensiva - Subtarefas A e B (Prazo: 27/07/2020 - 40%)\n",
        "\n",
        "- Resultado da subtarefa A para um conjunto de teste a ser fornecido\n",
        "- Resultado da subtarefa B para um conjunto de teste a ser fornecido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRQvNpQ79NTF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYmShHnx9IUF",
        "colab_type": "text"
      },
      "source": [
        "<b> ATIVIDADE 01 (parcial)</b>\n",
        "  - Leitura do arquivo txt (tratar os tweets separadamente)\n",
        "  - Tratamento de hashtags, menções, emojis e símbolos especiais, valores, datas\n",
        "  - Separação das sentenças e Tokenização\n",
        "  - Remoção stop-words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MRHH-jFQ9NhR"
      },
      "source": [
        "<b> Carregamento do arquivo de dados e transformação em DataFrame </b>\n",
        "\n",
        "É realizado o download do arquivo e instanciado um DataFrame com os dados. A variável do DataFrame é chamada 'tweets'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPX5dwMB9Fwb",
        "colab_type": "code",
        "outputId": "8862ab04-90fd-4a27-87d6-b920fcd61116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "import pandas as pd\n",
        "#download o arquivo localizado no reposítório do projeto\n",
        "!curl --remote-name \\\n",
        "    -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "    --location https://raw.githubusercontent.com/eduardodut/Mineracao_dados_textos_web/master/datasets/olid-training-v1.0.tsv\n",
        "\n",
        "#leitura para objeto dataframe\n",
        "tweets = pd.read_csv('/content/olid-training-v1.0.tsv', sep='\\t',encoding= 'utf-8')\n",
        "\n",
        "#conversão da coluna 'id' de inteiro para string\n",
        "tweets['id'] = tweets['id'].astype('str')\n",
        "\n",
        "#visualização dos primeiros registros\n",
        "tweets.head(20)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1915k  100 1915k    0     0  6200k      0 --:--:-- --:--:-- --:--:-- 6180k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>77444</td>\n",
              "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>52415</td>\n",
              "      <td>@USER was literally just talking about this lo...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>GRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>45157</td>\n",
              "      <td>@USER Buy more icecream!!!</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>82776</td>\n",
              "      <td>@USER @USER @USER It’s not my fault you suppor...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>42992</td>\n",
              "      <td>@USER What’s the difference between #Kavanaugh...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>28414</td>\n",
              "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>54920</td>\n",
              "      <td>@USER @USER @USER It should scare every Americ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>56392</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>86735</td>\n",
              "      <td>@USER you are also the king of taste</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>95686</td>\n",
              "      <td>#MAGA @USER  🎶 Sing like no one is listening  ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>71446</td>\n",
              "      <td>5/5: @USER The time is right for this House to...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>23958</td>\n",
              "      <td>@USER Besides Jax’s mom and maybe Ope he is ha...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>28195</td>\n",
              "      <td>@USER @USER @USER gun control! That is all the...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... subtask_c\n",
              "0   86426  ...       NaN\n",
              "1   90194  ...       IND\n",
              "2   16820  ...       NaN\n",
              "3   62688  ...       NaN\n",
              "4   43605  ...       NaN\n",
              "5   97670  ...       OTH\n",
              "6   77444  ...       NaN\n",
              "7   52415  ...       GRP\n",
              "8   45157  ...       NaN\n",
              "9   13384  ...       IND\n",
              "10  82776  ...       NaN\n",
              "11  42992  ...       NaN\n",
              "12  28414  ...       IND\n",
              "13  54920  ...       NaN\n",
              "14  56392  ...       NaN\n",
              "15  86735  ...       NaN\n",
              "16  95686  ...       NaN\n",
              "17  71446  ...       NaN\n",
              "18  23958  ...       NaN\n",
              "19  28195  ...       OTH\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNEs_dMiA3vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop das colunas que começam com 'sub'\n",
        "tweets.drop(tweets.columns[tweets.columns.str.startswith('sub')], axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwWEaIDEcwF",
        "colab_type": "code",
        "outputId": "49a01256-8dc3-4726-c4a8-2a8f89eb2196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#verificação e remoção de duplicatas\n",
        "if tweets.duplicated(['tweet']).sum()>0:\n",
        "  tweets.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
        "\n",
        "print('VALORES DUPLICADOS: ',tweets.duplicated(['tweet']).sum())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VALORES DUPLICADOS:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYbiDjILOK5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVAbRxcTLQZ0"
      },
      "source": [
        "<b> Tratamento inicial do texto </b>\n",
        "\n",
        "Converte o texto de cada tweet, separadamente, em minúsculo e remove espaços e tabulações extras. O resultado é guardado no DataFrame tweets em uma nova coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqS-1g3Kwgi",
        "colab_type": "code",
        "outputId": "fb782e2f-7ad7-475f-d13b-baee46c7221f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "def tratamento_texto(tweet):\n",
        "  \n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.strip()\n",
        "  \n",
        "  #remove as menções a usuários de cada tweet\n",
        "  tweet = re.sub(r'@user', '', tweet, flags=re.MULTILINE)\n",
        "  \n",
        "  #remove as quebras de linha\n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  #substitui tabulações por um espaço em branco\n",
        "  tweet = re.sub(r'\\t', ' ', tweet)\n",
        "  #substitui um ou mais espaços em branco por um espaço\n",
        "  tweet= re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
        "  #&amp;\n",
        "  #remove aspas e apóstofres\n",
        "  tweet = re.sub('[\\'\"‘’“”…]', '', tweet)\n",
        "  return tweet\n",
        "\n",
        "#cria uma nova coluna no dataframe 'tweets' com cada tweet tokenizado\n",
        "tweets['tweet_tratado'] = tweets['tweet'].apply(tratamento_texto)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go home youre drunk!!! #maga #trump2020 👊🇺🇸👊 url</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_tratado  ...     id\n",
              "0   she should ask a few native americans what th...  ...  86426\n",
              "1   go home youre drunk!!! #maga #trump2020 👊🇺🇸👊 url  ...  90194\n",
              "2  amazon is investigating chinese employees who ...  ...  16820\n",
              "3   someone shouldvetaken this piece of shit to a...  ...  62688\n",
              "4   obama wanted liberals &amp; illegals to move ...  ...  43605\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzoy4baWLizj"
      },
      "source": [
        "<b> Separação em sentenças </b>\n",
        "\n",
        "Separa cada tweet em sentenças e os coloca no DataFrame, em uma nova coluna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qma4M_noK4zu",
        "colab_type": "code",
        "outputId": "dc50048f-5c4d-4994-9e99-7d560170ebb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "import nltk\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "  nltk.download(\"stopwords\") \n",
        "  nltk.download('punkt')\n",
        "\n",
        "def separa_sentencas(tweet):\n",
        "  \n",
        "  lista_sentencas = sent_tokenize(tweet)\n",
        "  # lista_setencas.str.strip()\n",
        "  nova_lista = []\n",
        "  for sent in lista_sentencas:\n",
        "    nova_lista.append(sent.strip())\n",
        "\n",
        "  return nova_lista #retorna lista de sentenças com a função .strip() aplicada\n",
        "tweets['tweet_em_sentencas'] = tweets['tweet_tratado'].apply(separa_sentencas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[go home youre drunk!!!, #maga #trump2020 👊🇺🇸👊...</td>\n",
              "      <td>go home youre drunk!!! #maga #trump2020 👊🇺🇸👊 url</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  tweet_em_sentencas  ...     id\n",
              "0  [she should ask a few native americans what th...  ...  86426\n",
              "1  [go home youre drunk!!!, #maga #trump2020 👊🇺🇸👊...  ...  90194\n",
              "2  [amazon is investigating chinese employees who...  ...  16820\n",
              "3  [someone shouldvetaken this piece of shit to a...  ...  62688\n",
              "4  [obama wanted liberals &amp; illegals to move ...  ...  43605\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TZXVEs_1L3dj"
      },
      "source": [
        "<b> Tokenização </b>\n",
        "\n",
        "Reúne as sentenças em uma string única e realiza a tokenização do tweet. O resultado pode ser observado em uma nova coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y7Kz7aOLCzn",
        "colab_type": "code",
        "outputId": "1f9aa81f-7d21-47ba-9147-35efa192a109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "def tokeniza_sentenca(lista_sentencas):\n",
        "  tokenizer = TweetTokenizer()\n",
        "  #união das sentenças\n",
        "  sentencas_unidas = \" \".join(w for w in lista_sentencas)\n",
        "  #tokenização das sentenças unidas\n",
        "  tokens = tokenizer.tokenize(sentencas_unidas)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tweets['tweet_tokenizado'] = tweets['tweet_em_sentencas'].apply(tokeniza_sentenca)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[go, home, youre, drunk, !, !, !, #maga, #trum...</td>\n",
              "      <td>[go home youre drunk!!!, #maga #trump2020 👊🇺🇸👊...</td>\n",
              "      <td>go home youre drunk!!! #maga #trump2020 👊🇺🇸👊 url</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[someone, shouldvetaken, this, piece, of, shit...</td>\n",
              "      <td>[someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tweet_tokenizado  ...     id\n",
              "0  [she, should, ask, a, few, native, americans, ...  ...  86426\n",
              "1  [go, home, youre, drunk, !, !, !, #maga, #trum...  ...  90194\n",
              "2  [amazon, is, investigating, chinese, employees...  ...  16820\n",
              "3  [someone, shouldvetaken, this, piece, of, shit...  ...  62688\n",
              "4  [obama, wanted, liberals, &, illegals, to, mov...  ...  43605\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I36muOKnMD4D"
      },
      "source": [
        "<b> Remoção de stop words </b>\n",
        "\n",
        "Remove da lista de tokens de cada tweet as stop words da língua inglesa e pontuações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcCFILRLFFp",
        "colab_type": "code",
        "outputId": "ec977f61-fff5-4e8e-fda0-8bcba3069715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "# import string library function  \n",
        "from string import punctuation\n",
        "    \n",
        "\n",
        "\n",
        "def remove_stop_words(lista_tokens):\n",
        "  \n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "\n",
        "  tokens = [w for w in lista_tokens if not w in stop_words]\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tweets['tokens_sem_stopwords'] = tweets['tweet_tokenizado'].apply(remove_stop_words)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens_sem_stopwords</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ask, native, americans, take]</td>\n",
              "      <td>[she, should, ask, a, few, native, americans, ...</td>\n",
              "      <td>[she should ask a few native americans what th...</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[go, home, youre, drunk, #maga, #trump2020, 👊,...</td>\n",
              "      <td>[go, home, youre, drunk, !, !, !, #maga, #trum...</td>\n",
              "      <td>[go home youre drunk!!!, #maga #trump2020 👊🇺🇸👊...</td>\n",
              "      <td>go home youre drunk!!! #maga #trump2020 👊🇺🇸👊 url</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[amazon, investigating, chinese, employees, se...</td>\n",
              "      <td>[amazon, is, investigating, chinese, employees...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[someone, shouldvetaken, piece, shit, volcano, 😂]</td>\n",
              "      <td>[someone, shouldvetaken, this, piece, of, shit...</td>\n",
              "      <td>[someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[obama, wanted, liberals, illegals, move, red,...</td>\n",
              "      <td>[obama, wanted, liberals, &amp;, illegals, to, mov...</td>\n",
              "      <td>[obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>obama wanted liberals &amp;amp; illegals to move ...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                tokens_sem_stopwords  ...     id\n",
              "0                     [ask, native, americans, take]  ...  86426\n",
              "1  [go, home, youre, drunk, #maga, #trump2020, 👊,...  ...  90194\n",
              "2  [amazon, investigating, chinese, employees, se...  ...  16820\n",
              "3  [someone, shouldvetaken, piece, shit, volcano, 😂]  ...  62688\n",
              "4  [obama, wanted, liberals, illegals, move, red,...  ...  43605\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}