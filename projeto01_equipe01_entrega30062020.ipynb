{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "projeto01_equipe01_entrega27042020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodut/Mineracao_dados_textos_web/blob/master/projeto01_equipe01_entrega30062020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDkhltJeg5ag",
        "colab_type": "text"
      },
      "source": [
        "<b> EQUIPE: </b>\n",
        "  - Eduardo Façanha\n",
        "  - Giovanni Brígido\n",
        "  - Maurício Brito\n",
        "\n",
        "<b> ATIVIDADE 01 </b> - Pré-processamento dos textos (Prazo: 11/05/2020 - 30%)\n",
        "\n",
        "- Tokenização\n",
        "- Lematização\n",
        "- POS Tagging\n",
        "- Normalização (hashtags, menções, emojis e símbolos especiais)\n",
        "- Chunking\n",
        "- NER (entidades nomeadas)\n",
        "- Remoção stop-words\n",
        "\n",
        "<b> ATIVIDADE 02 </b> - Representação Semântica (Prazo: 30/06/2020 - 30%)\n",
        "\n",
        "- Uso de bases de conhecimento externas\n",
        "- Identificação de tópicos\n",
        "- Representação vetorial das palavras e textos\n",
        "\n",
        "<b> ATIVIDADE 03 </b> - Analise da Linguagem Ofensiva - Subtarefas A e B (Prazo: 30/07/2020 - 40%)\n",
        "\n",
        "- Resultado da subtarefa A para um conjunto de teste a ser fornecido\n",
        "- Resultado da subtarefa B para um conjunto de teste a ser fornecido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MRHH-jFQ9NhR"
      },
      "source": [
        "<b> Carregamento do arquivo de dados e transformação em DataFrame </b>\n",
        "\n",
        "É realizado o download do arquivo e instanciado um DataFrame com os dados. A variável do DataFrame é chamada 'tweets'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPX5dwMB9Fwb",
        "colab_type": "code",
        "outputId": "5e5ba7ea-b417-4884-a8d8-47f25d06bd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "import pandas as pd\n",
        "#download o arquivo localizado no reposítório do projeto\n",
        "!curl --remote-name \\\n",
        "    -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "    --location https://raw.githubusercontent.com/eduardodut/Mineracao_dados_textos_web/master/datasets/olid-training-v1.0.tsv\n",
        "\n",
        "#leitura para objeto dataframe\n",
        "tweets = pd.read_csv('/content/olid-training-v1.0.tsv', sep='\\t',encoding= 'utf-8')\n",
        "\n",
        "#conversão da coluna 'id' de inteiro para string\n",
        "tweets['id'] = tweets['id'].astype('str')\n",
        "\n",
        "#visualização dos primeiros registros\n",
        "\n",
        "tweets = tweets[['subtask_c','subtask_b','subtask_a','id','tweet']]\n",
        "tweets.head(20)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1915k  100 1915k    0     0  2970k      0 --:--:-- --:--:-- --:--:-- 2970k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>UNT</td>\n",
              "      <td>OFF</td>\n",
              "      <td>77444</td>\n",
              "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GRP</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>52415</td>\n",
              "      <td>@USER was literally just talking about this lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>45157</td>\n",
              "      <td>@USER Buy more icecream!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>82776</td>\n",
              "      <td>@USER @USER @USER It’s not my fault you suppor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>42992</td>\n",
              "      <td>@USER What’s the difference between #Kavanaugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>IND</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28414</td>\n",
              "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>54920</td>\n",
              "      <td>@USER @USER @USER It should scare every Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>56392</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>86735</td>\n",
              "      <td>@USER you are also the king of taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>95686</td>\n",
              "      <td>#MAGA @USER  🎶 Sing like no one is listening  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>71446</td>\n",
              "      <td>5/5: @USER The time is right for this House to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "      <td>23958</td>\n",
              "      <td>@USER Besides Jax’s mom and maybe Ope he is ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OTH</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OFF</td>\n",
              "      <td>28195</td>\n",
              "      <td>@USER @USER @USER gun control! That is all the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subtask_c  ...                                              tweet\n",
              "0        NaN  ...  @USER She should ask a few native Americans wh...\n",
              "1        IND  ...  @USER @USER Go home you’re drunk!!! @USER #MAG...\n",
              "2        NaN  ...  Amazon is investigating Chinese employees who ...\n",
              "3        NaN  ...  @USER Someone should'veTaken\" this piece of sh...\n",
              "4        NaN  ...  @USER @USER Obama wanted liberals &amp; illega...\n",
              "5        OTH  ...                  @USER Liberals are all Kookoo !!!\n",
              "6        NaN  ...                   @USER @USER Oh noes! Tough shit.\n",
              "7        GRP  ...  @USER was literally just talking about this lo...\n",
              "8        NaN  ...                         @USER Buy more icecream!!!\n",
              "9        IND  ...  @USER Canada doesn’t need another CUCK! We alr...\n",
              "10       NaN  ...  @USER @USER @USER It’s not my fault you suppor...\n",
              "11       NaN  ...  @USER What’s the difference between #Kavanaugh...\n",
              "12       IND  ...  @USER you are a lying corrupt traitor!!! Nobod...\n",
              "13       NaN  ...  @USER @USER @USER It should scare every Americ...\n",
              "14       NaN  ...  @USER @USER @USER @USER @USER @USER @USER @USE...\n",
              "15       NaN  ...               @USER you are also the king of taste\n",
              "16       NaN  ...  #MAGA @USER  🎶 Sing like no one is listening  ...\n",
              "17       NaN  ...  5/5: @USER The time is right for this House to...\n",
              "18       NaN  ...  @USER Besides Jax’s mom and maybe Ope he is ha...\n",
              "19       OTH  ...  @USER @USER @USER gun control! That is all the...\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwWEaIDEcwF",
        "colab_type": "code",
        "outputId": "624ddca1-7e24-4fd2-90f5-af6732332af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#verificação e remoção de duplicatas\n",
        "if tweets.duplicated(['tweet']).sum()>0:\n",
        "  tweets.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
        "\n",
        "print('TWEETS DUPLICADOS: ',tweets.duplicated(['tweet']).sum())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TWEETS DUPLICADOS:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVAbRxcTLQZ0"
      },
      "source": [
        "<b> Tratamento inicial do texto </b>\n",
        "\n",
        "Converte o texto de cada tweet, separadamente, em minúsculo e remove espaços e tabulações extras. O resultado é guardado no DataFrame tweets em uma nova coluna.\n",
        "\n",
        "Entrada: tweets['tweet']<br/>\n",
        "Saída: tweets['tweet_tratado']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqS-1g3Kwgi",
        "colab_type": "code",
        "outputId": "1f9a8d58-3f9b-4aad-e2b7-f76d27a8b76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "def tratamento_texto(tweet):\n",
        "  \n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.strip()\n",
        "  \n",
        "  #remove as menções a usuários de cada tweet\n",
        "  # tweet = re.sub(r'@user', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as palavras url\n",
        "  tweet = re.sub(r'url', '', tweet, flags=re.MULTILINE)\n",
        "  #remove as quebras de linha\n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  #substitui tabulações por um espaço em branco\n",
        "  tweet = re.sub(r'\\t', ' ', tweet)\n",
        "  #substitui um ou mais espaços em branco por um espaço\n",
        "  tweet= re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
        "  #&amp;\n",
        "  #remove aspas e apóstofres\n",
        "  # tweet = re.sub('[\\'\"‘’“”…]', '', tweet)\n",
        "  return tweet\n",
        "\n",
        "#cria uma nova coluna no dataframe 'tweets' com cada tweet tokenizado\n",
        "tweets['tweet_tratado'] = tweets['tweet'].apply(tratamento_texto)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_tratado  ... subtask_c\n",
              "0  @user she should ask a few native americans wh...  ...       NaN\n",
              "1  @user @user go home you’re drunk!!! @user #mag...  ...       IND\n",
              "2  amazon is investigating chinese employees who ...  ...       NaN\n",
              "3  @user someone should'vetaken\" this piece of sh...  ...       NaN\n",
              "4  @user @user obama wanted liberals &amp; illega...  ...       NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzoy4baWLizj"
      },
      "source": [
        "<b> Separação em sentenças </b>\n",
        "\n",
        "Separa cada tweet em sentenças.\n",
        "\n",
        "Entrada: tweets['tweet_tratado']<br/>\n",
        "Saída: tweets['tweet_em_sentencas']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qma4M_noK4zu",
        "colab_type": "code",
        "outputId": "fd07282d-5d47-42bc-8f47-3d9873fe78c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import nltk\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "  nltk.download(\"stopwords\") \n",
        "  nltk.download('punkt')\n",
        "\n",
        "def separa_sentencas(tweet):\n",
        "  \n",
        "  lista_sentencas = sent_tokenize(tweet)\n",
        "  # lista_setencas.str.strip()\n",
        "  nova_lista = []\n",
        "  for sent in lista_sentencas:\n",
        "    nova_lista.append(sent.strip())\n",
        "\n",
        "  return nova_lista #retorna lista de sentenças com a função .strip() aplicada\n",
        "tweets['tweet_em_sentencas'] = tweets['tweet_tratado'].apply(separa_sentencas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  tweet_em_sentencas  ... subtask_c\n",
              "0  [@user she should ask a few native americans w...  ...       NaN\n",
              "1  [@user @user go home you’re drunk!!!, @user #m...  ...       IND\n",
              "2  [amazon is investigating chinese employees who...  ...       NaN\n",
              "3  [@user someone should'vetaken\" this piece of s...  ...       NaN\n",
              "4  [@user @user obama wanted liberals &amp; illeg...  ...       NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TZXVEs_1L3dj"
      },
      "source": [
        "<b> Tokenização </b>\n",
        "\n",
        "Tokenização do tweet.\n",
        "\n",
        "Entrada: tweets['tweet_em_sentencas']<br/>\n",
        "Saída: tweets['tweet_tokenizado']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y7Kz7aOLCzn",
        "colab_type": "code",
        "outputId": "3e5f739d-40ca-436f-8162-cb9c3b3d7df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "def tokeniza_sentenca(lista_sentencas):\n",
        "  # tokenizer = TweetTokenizer()\n",
        "  # #união das sentenças\n",
        "  # sentencas_unidas = \" \".join(w for w in lista_sentencas)\n",
        "  # #tokenização das sentenças unidas\n",
        "  # tokens = tokenizer.tokenize(sentencas_unidas)\n",
        "\n",
        "  tokenizer = TweetTokenizer()\n",
        "  tokens = []\n",
        "\n",
        "  for sentenca in lista_sentencas:\n",
        "\n",
        "    tokens.append(tokenizer.tokenize(sentenca))\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tweets['tweet_tokenizado'] = tweets['tweet_em_sentencas'].apply(tokeniza_sentenca)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[@user, she, should, ask, a, few, native, ame...</td>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[@user, @user, go, home, you, ’, re, drunk, !...</td>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[@user, someone, should'vetaken, \", this, pie...</td>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, &amp;, il...</td>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tweet_tokenizado  ... subtask_c\n",
              "0  [[@user, she, should, ask, a, few, native, ame...  ...       NaN\n",
              "1  [[@user, @user, go, home, you, ’, re, drunk, !...  ...       IND\n",
              "2  [[amazon, is, investigating, chinese, employee...  ...       NaN\n",
              "3  [[@user, someone, should'vetaken, \", this, pie...  ...       NaN\n",
              "4  [[@user, @user, obama, wanted, liberals, &, il...  ...       NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gc2ojEgN8CAz"
      },
      "source": [
        "<b> POS Tagger </b>\n",
        "\n",
        "Realiza a part of speech tagging do texto de cada token\n",
        "\n",
        "Entrada: tweets['tweet_tokenizado']<br/>\n",
        "Saída: tweets['tweet_POS_tagged']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO70tP5r8NtQ",
        "colab_type": "code",
        "outputId": "485db55c-e1d4-442c-85d7-2c864d91f334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "# a função map aplica a funcao nltk.post_tag para cada lista contida da coluna tweet tokenizado\n",
        " \n",
        "def pos_taggeador(lista_tokens):\n",
        "  setenca_taggeada = []\n",
        "  for lista in lista_tokens:\n",
        "    setenca_taggeada.append(nltk.pos_tag(lista))\n",
        "\n",
        "  return setenca_taggeada\n",
        "\n",
        "                                                        #apply(nltk.pos) se a coluna for composta de lista de tokens\n",
        "tweets['tweet_POS_tagged'] = tweets['tweet_tokenizado'].apply(pos_taggeador)#\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[@user, she, should, ask, a, few, native, ame...</td>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[@user, @user, go, home, you, ’, re, drunk, !...</td>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[@user, someone, should'vetaken, \", this, pie...</td>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, &amp;, il...</td>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tweet_POS_tagged  ... subtask_c\n",
              "0  [[(@user, IN), (she, PRP), (should, MD), (ask,...  ...       NaN\n",
              "1  [[(@user, NNP), (@user, NNP), (go, VBP), (home...  ...       IND\n",
              "2  [[(amazon, NN), (is, VBZ), (investigating, VBG...  ...       NaN\n",
              "3  [[(@user, NN), (someone, NN), (should'vetaken,...  ...       NaN\n",
              "4  [[(@user, NNP), (@user, NNP), (obama, NN), (wa...  ...       NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGo5JNKZuK-N",
        "colab_type": "text"
      },
      "source": [
        "**Chunking**\n",
        "\n",
        "Separação de cada sentença em chunks. \n",
        "\n",
        "Entrada: tweets['tweet_POS_tagged']<br/>\n",
        "Saída: tweets['tweet_chunked']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0Uhw6uuLR7",
        "colab_type": "code",
        "outputId": "194765c8-b595-45ce-f161-7c2c6f901382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "\n",
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "pattern1 = 'NP: {<DT>?<JJ>*<NN.*>*}'\n",
        "pattern2 = 'NP: {<DT><NN.*><.*>*<NN.*>}'\n",
        "\n",
        "def chunker(lista_tweets_pos_tagged):\n",
        "\n",
        "  lista_saida = []\n",
        "\n",
        "  pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "  pattern1 = 'NP: {<DT>?<JJ>*<NN.*>*}'\n",
        "  pattern2 = 'NP: {<DT><NN.*><.*>*<NN.*>}'\n",
        "\n",
        "\n",
        "  for lista in lista_tweets_pos_tagged:\n",
        "    cp = nltk.RegexpParser(pattern1)\n",
        "    cs = cp.parse(lista)\n",
        "    iob_tagged = tree2conlltags(cs)\n",
        "    \n",
        "    lista_saida.append(iob_tagged)\n",
        "  return lista_saida\n",
        "\n",
        "\n",
        "tweets['tweet_chunked'] = tweets['tweet_POS_tagged'].apply(chunker)\n",
        "\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_chunked</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(@user, IN, O), (she, PRP, O), (should, MD, ...</td>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[@user, she, should, ask, a, few, native, ame...</td>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[@user, @user, go, home, you, ’, re, drunk, !...</td>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN, B-NP), (is, VBZ, O), (investiga...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(@user, NN, B-NP), (someone, NN, I-NP), (sho...</td>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[@user, someone, should'vetaken, \", this, pie...</td>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, &amp;, il...</td>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_chunked  ... subtask_c\n",
              "0  [[(@user, IN, O), (she, PRP, O), (should, MD, ...  ...       NaN\n",
              "1  [[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...  ...       IND\n",
              "2  [[(amazon, NN, B-NP), (is, VBZ, O), (investiga...  ...       NaN\n",
              "3  [[(@user, NN, B-NP), (someone, NN, I-NP), (sho...  ...       NaN\n",
              "4  [[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...  ...       NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSeX_Mt8DnbX"
      },
      "source": [
        "<b> NER </b>\n",
        "\n",
        "Realiza a reconhecimento de entidades, NER.\n",
        "\n",
        "Entrada: tweets['tweet_POS_tagged']<br/>\n",
        "Saída: tweets['tweet_NER']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc78e1ae-46d3-494f-fc4d-4ded55dce71d",
        "id": "U9gYrTCrDnbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "from nltk.chunk.regexp import ChunkString, ChunkRule, ChinkRule \n",
        "from nltk.tree import Tree \n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "    nltk.download('words')\n",
        "\n",
        "def ner(lista_tokens_taggeados):\n",
        "  lista_tokens_ner = []\n",
        "  for lista in lista_tokens_taggeados:\n",
        "    lista_tokens_ner.append(nltk.ne_chunk(lista))\n",
        "\n",
        "  return lista_tokens_ner\n",
        "\n",
        "\n",
        "tweets['tweet_NER'] = tweets['tweet_POS_tagged'].apply(ner)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_chunked</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[(@user, IN, O), (she, PRP, O), (should, MD, ...</td>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[@user, she, should, ask, a, few, native, ame...</td>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[@user, @user, go, home, you, ’, re, drunk, !...</td>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[(amazon, NN, B-NP), (is, VBZ, O), (investiga...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[(@user, NN, B-NP), (someone, NN, I-NP), (sho...</td>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[@user, someone, should'vetaken, \", this, pie...</td>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, &amp;, il...</td>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_NER  ... subtask_c\n",
              "0  [[(@user, IN), (she, PRP), (should, MD), (ask,...  ...       NaN\n",
              "1  [[(@user, NNP), (@user, NNP), (go, VBP), (home...  ...       IND\n",
              "2  [[(amazon, NN), (is, VBZ), (investigating, VBG...  ...       NaN\n",
              "3  [[(@user, NN), (someone, NN), (should'vetaken,...  ...       NaN\n",
              "4  [[(@user, NNP), (@user, NNP), (obama, NN), (wa...  ...       NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I36muOKnMD4D"
      },
      "source": [
        "<b> Remoção de stop words </b>\n",
        "\n",
        "Remove da lista de tokens de cada tweet as stop words da língua inglesa e pontuações.\n",
        "\n",
        "Entradas:<br/>\n",
        "         * tweets['tweet_tokenizado']<br/>\n",
        "         * tweets['tweet_ner']<br/>\n",
        "         * tweets['tweet_chunked']<br/>\n",
        "\n",
        "Saída:<br/>\n",
        "         * tweets['tokens_sem_stopwords']<br/>\n",
        "         * tweets['NER_sem_stopwords'] <br/>\n",
        "         * tweets['chunks_sem_stopwords']<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcCFILRLFFp",
        "colab_type": "code",
        "outputId": "a7be5eb6-86b3-43d8-eb29-9f8df80ac589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "# import string library function  \n",
        "from string import punctuation\n",
        "    \n",
        "\n",
        "\n",
        "def remove_stop_words(lista_token_sentenca):\n",
        "  '''Função de remoção de stop word que recebe lista de tokens e devolve\n",
        "  lista de tokens\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "\n",
        "  lista_saida = []\n",
        "\n",
        "  for lista_tokens in lista_token_sentenca:\n",
        "    tokens = [w for w in lista_tokens if not w in stop_words]\n",
        "    lista_saida.append(tokens)\n",
        "\n",
        "\n",
        "  return lista_saida\n",
        "\n",
        "def remove_stop_words_tuplas(lista_tuplas_sentencas):\n",
        "  '''Função de remoção de stop word que recebe lista de tuplas de token e tag e devolve\n",
        "  lista de tuplas de token e tag\n",
        "  '''\n",
        "  with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\") \n",
        "    nltk.download('punkt')\n",
        "  \n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(punctuation ))\n",
        "  lista_saida = []\n",
        "  for lista_tuplas in lista_tuplas_sentencas:\n",
        "    tuplas = [w for w in lista_tuplas if not w[0] in stop_words]\n",
        "    lista_saida.append(tuplas)\n",
        "  return lista_saida\n",
        "\n",
        "tweets['tokens_sem_stopwords'] = tweets['tweet_tokenizado'].apply(remove_stop_words)\n",
        "tweets['NER_sem_stopwords'] = tweets['tweet_NER'].apply(remove_stop_words_tuplas)\n",
        "tweets['chunks_sem_stopwords'] = tweets['tweet_chunked'].apply(remove_stop_words_tuplas)\n",
        "tweets[tweets.columns[::-1]].head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunks_sem_stopwords</th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>tokens_sem_stopwords</th>\n",
              "      <th>tweet_NER</th>\n",
              "      <th>tweet_chunked</th>\n",
              "      <th>tweet_POS_tagged</th>\n",
              "      <th>tweet_tokenizado</th>\n",
              "      <th>tweet_em_sentencas</th>\n",
              "      <th>tweet_tratado</th>\n",
              "      <th>tweet</th>\n",
              "      <th>id</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(@user, IN, O), (ask, VB, O), (native, JJ, I...</td>\n",
              "      <td>[[(@user, IN), (ask, VB), (native, JJ), (ameri...</td>\n",
              "      <td>[[@user, ask, native, americans, take]]</td>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[(@user, IN, O), (she, PRP, O), (should, MD, ...</td>\n",
              "      <td>[[(@user, IN), (she, PRP), (should, MD), (ask,...</td>\n",
              "      <td>[[@user, she, should, ask, a, few, native, ame...</td>\n",
              "      <td>[@user she should ask a few native americans w...</td>\n",
              "      <td>@user she should ask a few native americans wh...</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>86426</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[@user, @user, go, home, ’, drunk], [@user, #...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (go, VBP), (home...</td>\n",
              "      <td>[[@user, @user, go, home, you, ’, re, drunk, !...</td>\n",
              "      <td>[@user @user go home you’re drunk!!!, @user #m...</td>\n",
              "      <td>@user @user go home you’re drunk!!! @user #mag...</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>90194</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
              "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
              "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[(amazon, NN, B-NP), (is, VBZ, O), (investiga...</td>\n",
              "      <td>[[(amazon, NN), (is, VBZ), (investigating, VBG...</td>\n",
              "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
              "      <td>[amazon is investigating chinese employees who...</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>16820</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(@user, NN, B-NP), (someone, NN, I-NP), (sho...</td>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[@user, someone, should'vetaken, piece, shit,...</td>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[(@user, NN, B-NP), (someone, NN, I-NP), (sho...</td>\n",
              "      <td>[[(@user, NN), (someone, NN), (should'vetaken,...</td>\n",
              "      <td>[[@user, someone, should'vetaken, \", this, pie...</td>\n",
              "      <td>[@user someone should'vetaken\" this piece of s...</td>\n",
              "      <td>@user someone should'vetaken\" this piece of sh...</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>62688</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, illeg...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...</td>\n",
              "      <td>[[(@user, NNP), (@user, NNP), (obama, NN), (wa...</td>\n",
              "      <td>[[@user, @user, obama, wanted, liberals, &amp;, il...</td>\n",
              "      <td>[@user @user obama wanted liberals &amp;amp; illeg...</td>\n",
              "      <td>@user @user obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>43605</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                chunks_sem_stopwords  ... subtask_c\n",
              "0  [[(@user, IN, O), (ask, VB, O), (native, JJ, I...  ...       NaN\n",
              "1  [[(@user, NNP, B-NP), (@user, NNP, I-NP), (go,...  ...       IND\n",
              "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...  ...       NaN\n",
              "3  [[(@user, NN, B-NP), (someone, NN, I-NP), (sho...  ...       NaN\n",
              "4  [[(@user, NNP, B-NP), (@user, NNP, I-NP), (oba...  ...       NaN\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gpvnfgkKLFB5"
      },
      "source": [
        "<b> Fim da atividade 01 </b>\n",
        "\n",
        "Tem-se como principais entregas as colunas tweets['tokens_sem_stopwords'] e tweets['NER_sem_stopwords'] do dataset tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0KRyOaLU5H",
        "colab_type": "code",
        "outputId": "f439130b-cd4b-4af6-b6bb-6ef0244df0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "tweets[['NER_sem_stopwords','chunks_sem_stopwords']].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER_sem_stopwords</th>\n",
              "      <th>chunks_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(ask, VB), (native, JJ), (americans, NNS), (...</td>\n",
              "      <td>[[(ask, VB, O), (native, JJ, I-NP), (americans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(go, VB), (home, NN), (’, VBP), (drunk, NN)]...</td>\n",
              "      <td>[[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
              "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(someone, NN), (should'vetaken, VBD), (piece...</td>\n",
              "      <td>[[(someone, NN, B-NP), (should'vetaken, VBD, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
              "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   NER_sem_stopwords                               chunks_sem_stopwords\n",
              "0  [[(ask, VB), (native, JJ), (americans, NNS), (...  [[(ask, VB, O), (native, JJ, I-NP), (americans...\n",
              "1  [[(go, VB), (home, NN), (’, VBP), (drunk, NN)]...  [[(go, VB, O), (home, NN, B-NP), (’, VBP, O), ...\n",
              "2  [[(amazon, NN), (investigating, VBG), (chinese...  [[(amazon, NN, B-NP), (investigating, VBG, O),...\n",
              "3  [[(someone, NN), (should'vetaken, VBD), (piece...  [[(someone, NN, B-NP), (should'vetaken, VBD, O...\n",
              "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...  [[(obama, RB, O), (wanted, VBD, O), (liberals,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InGHhHvvJml2",
        "colab_type": "text"
      },
      "source": [
        "base externa: wordnet lemmatizer?\n",
        "Não deixar palavras de meio de sentença em minúsculo pois podem ser entidades\n",
        "identificar \"typos\"\n",
        "Remover n-grams de alta frequência (não adicionam informação), e de  baixa frequência com erros (para prevenir overfit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkVlpDzLWf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "texts = [\n",
        "    \"good movie\", \"not a good movie\", \"did not like\", \n",
        "    \"i like it\", \"good one\"\n",
        "]\n",
        "# using default tokenizer in TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}